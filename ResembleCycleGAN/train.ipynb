{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from dataset import ResembleDataset\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "from torchvision.utils import save_image\n",
    "from model import Discriminator, Generator\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "LAMBDA_IDENTITY = 0.0\n",
    "LAMBDA_CYCLE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(disc_H, disc_Z, gen_H, gen_Z, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
    "    l_reals = 0\n",
    "    l_fakes = 0\n",
    "\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (human, animal) in enumerate(loop):\n",
    "        human, animal = human.to(device), animal.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_animal = gen_H(human)\n",
    "\n",
    "            D_H_real = disc_H(animal)\n",
    "            D_H_fake = disc_H(fake_animal.detach())\n",
    "\n",
    "            l_reals += D_H_real.mean().item()\n",
    "            l_fakes += D_H_fake.mean().item()\n",
    "\n",
    "            # 1이라고 판별하면 옳은 거 \n",
    "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
    "            # 0이라고 판별해야 옳은 거 \n",
    "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
    "\n",
    "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
    "\n",
    "\n",
    "            fake_human = gen_Z(animal)\n",
    "\n",
    "            D_Z_real = disc_Z(human)\n",
    "            D_Z_fake = disc_Z(fake_animal)\n",
    "\n",
    "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
    "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
    "\n",
    "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
    "\n",
    "\n",
    "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
    "        \n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_H_fake = disc_H(fake_animal)\n",
    "            D_Z_fake = disc_Z(fake_human)\n",
    "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
    "            loss_G_Z = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
    "\n",
    "            # cycle loss\n",
    "            cycle_human = gen_Z(fake_animal)\n",
    "            cycle_animal = gen_H(fake_human)\n",
    "            cycle_human_loss = l1(human, cycle_human)\n",
    "            cycle_animal_loss = l1(animal, cycle_animal)\n",
    "\n",
    "            # identity loss => keep color theme\n",
    "            identity_animal = gen_Z(animal)\n",
    "            identity_human = gen_H(human)\n",
    "            identity_human_loss = l1(identity_human, human)\n",
    "            identity_animal_loss = l1(identity_animal, animal)\n",
    "\n",
    "            G_loss = (\n",
    "                loss_G_Z + loss_G_H + LAMBDA_CYCLE*cycle_human_loss + LAMBDA_CYCLE*cycle_animal_loss + LAMBDA_IDENTITY*identity_human_loss + LAMBDA_IDENTITY*identity_animal_loss\n",
    "            )\n",
    "\n",
    "            opt_gen.zero_grad()\n",
    "            g_scaler.scale(G_loss).backward()\n",
    "            g_scaler.step(opt_gen)\n",
    "            g_scaler.update()\n",
    "\n",
    "            if idx % 200 == 0:\n",
    "                save_image(fake_human * 0.5 + 0.5, f\"saved_images/human_{idx}.png\")\n",
    "                save_image(fake_animal*0.5+0.5, f\"saved_image/animal_{idx}.png\")\n",
    "\n",
    "            loop.set_postfix(l_reals=l_reals/(idx+1), l_fakes=l_fakes/(idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = Discriminator(in_channels=3).to(device)\n",
    "disc_Z = Discriminator(in_channels=3).to(device)\n",
    "gen_Z = Generator(img_channels=3, num_residuals=9).to(device)\n",
    "gen_H = Generator(img_channels=3, num_residuals=9).to(device)\n",
    "\n",
    "opt_disc = optim.Adam(\n",
    "    list(disc_H.parameters())+list(disc_Z.parameters()),\n",
    "    lr= learning_rate,betas=(0.5, 0.999)\n",
    ")\n",
    "opt_gen = optim.Adam(\n",
    "    list(gen_Z.parameters())+list(gen_H.parameters()),\n",
    "    lr= learning_rate,betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "path_human_image = \"../dataset/before/human/*\"\n",
    "path_animal_image = \"../dataset/before/animal/*\"\n",
    "    \n",
    "transform = T.Compose([T.Resize((256, 256), 0), T.ToTensor(),])\n",
    "\n",
    "dataset = ResembleDataset(path_human_image, path_animal_image, transform)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "nb_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nb_epochs):\n\u001b[1;32m----> 2\u001b[0m     train_loop(disc_H, disc_Z, gen_H, gen_Z, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(disc_H, disc_Z, gen_H, gen_Z, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler)\u001b[0m\n\u001b[0;32m      8\u001b[0m human, animal \u001b[39m=\u001b[39m human\u001b[39m.\u001b[39mto(device), animal\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m---> 11\u001b[0m     fake_animal \u001b[39m=\u001b[39m gen_H(human)\n\u001b[0;32m     13\u001b[0m     D_H_real \u001b[39m=\u001b[39m disc_H(animal)\n\u001b[0;32m     14\u001b[0m     D_H_fake \u001b[39m=\u001b[39m disc_H(fake_animal\u001b[39m.\u001b[39mdetach())\n",
      "File \u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:175\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "    train_loop(disc_H, disc_Z, gen_H, gen_Z, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
